{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebook though as you work through this.\n",
    "\n",
    "First off, let's load the dataset through torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6,  6,  2,  1,  7,  2,  2,  6,  7,  6,  1,  0,  2,  7,\n",
      "         5,  3,  3,  6,  4,  6,  1,  3,  8,  4,  6,  7,  7,  6,\n",
      "         8,  8,  8,  0,  7,  5,  8,  9,  6,  1,  2,  7,  3,  6,\n",
      "         9,  8,  9,  8,  9,  1,  7,  6,  3,  9,  7,  6,  6,  7,\n",
      "         7,  4,  4,  4,  7,  3,  0,  3])\n",
      "Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};\n",
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);\n",
    "print(label)\n",
    "print(labels_map[label[0].item()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded, it's time to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits from the forward pass. It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64,64,64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('fc3', nn.Linear(hidden_sizes[1], hidden_sizes[2])),\n",
    "                      ('relu3', nn.ReLU()),\n",
    "                      ('fc4', nn.Linear(hidden_sizes[2], hidden_sizes[3])),\n",
    "                      ('relu4', nn.ReLU()),\n",
    "                      ('logits', nn.Linear(hidden_sizes[3], output_size))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) ( something like `nn.CrossEntropyLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:40 1/10...  Loss: 2.2984\n",
      "Epoch:80 1/10...  Loss: 2.2201\n",
      "Epoch:120 1/10...  Loss: 1.7686\n",
      "Epoch:160 1/10...  Loss: 1.1670\n",
      "Epoch:200 1/10...  Loss: 0.9641\n",
      "Epoch:240 1/10...  Loss: 0.7966\n",
      "Epoch:280 1/10...  Loss: 0.7472\n",
      "Epoch:320 1/10...  Loss: 0.7344\n",
      "Epoch:360 1/10...  Loss: 0.6918\n",
      "Epoch:400 1/10...  Loss: 0.6995\n",
      "Epoch:440 1/10...  Loss: 0.6405\n",
      "Epoch:480 1/10...  Loss: 0.6192\n",
      "Epoch:520 1/10...  Loss: 0.6253\n",
      "Epoch:560 1/10...  Loss: 0.5658\n",
      "Epoch:600 1/10...  Loss: 0.5386\n",
      "Epoch:640 1/10...  Loss: 0.5171\n",
      "Epoch:680 1/10...  Loss: 0.5350\n",
      "Epoch:720 1/10...  Loss: 0.4942\n",
      "Epoch:760 1/10...  Loss: 0.5281\n",
      "Epoch:800 1/10...  Loss: 0.5049\n",
      "Epoch:840 1/10...  Loss: 0.4826\n",
      "Epoch:880 1/10...  Loss: 0.4639\n",
      "Epoch:920 1/10...  Loss: 0.4640\n",
      "Epoch:960 2/10...  Loss: 0.2777\n",
      "Epoch:1000 2/10...  Loss: 0.5324\n",
      "Epoch:1040 2/10...  Loss: 0.4501\n",
      "Epoch:1080 2/10...  Loss: 0.4242\n",
      "Epoch:1120 2/10...  Loss: 0.4041\n",
      "Epoch:1160 2/10...  Loss: 0.4747\n",
      "Epoch:1200 2/10...  Loss: 0.4669\n",
      "Epoch:1240 2/10...  Loss: 0.4343\n",
      "Epoch:1280 2/10...  Loss: 0.4171\n",
      "Epoch:1320 2/10...  Loss: 0.4447\n",
      "Epoch:1360 2/10...  Loss: 0.4362\n",
      "Epoch:1400 2/10...  Loss: 0.4405\n",
      "Epoch:1440 2/10...  Loss: 0.4388\n",
      "Epoch:1480 2/10...  Loss: 0.4029\n",
      "Epoch:1520 2/10...  Loss: 0.4241\n",
      "Epoch:1560 2/10...  Loss: 0.4407\n",
      "Epoch:1600 2/10...  Loss: 0.4111\n",
      "Epoch:1640 2/10...  Loss: 0.4452\n",
      "Epoch:1680 2/10...  Loss: 0.4050\n",
      "Epoch:1720 2/10...  Loss: 0.3593\n",
      "Epoch:1760 2/10...  Loss: 0.4268\n",
      "Epoch:1800 2/10...  Loss: 0.3883\n",
      "Epoch:1840 2/10...  Loss: 0.4034\n",
      "Epoch:1880 3/10...  Loss: 0.0380\n",
      "Epoch:1920 3/10...  Loss: 0.3960\n",
      "Epoch:1960 3/10...  Loss: 0.3898\n",
      "Epoch:2000 3/10...  Loss: 0.4010\n",
      "Epoch:2040 3/10...  Loss: 0.4016\n",
      "Epoch:2080 3/10...  Loss: 0.3980\n",
      "Epoch:2120 3/10...  Loss: 0.3919\n",
      "Epoch:2160 3/10...  Loss: 0.3784\n",
      "Epoch:2200 3/10...  Loss: 0.3879\n",
      "Epoch:2240 3/10...  Loss: 0.3836\n",
      "Epoch:2280 3/10...  Loss: 0.3873\n",
      "Epoch:2320 3/10...  Loss: 0.3628\n",
      "Epoch:2360 3/10...  Loss: 0.3924\n",
      "Epoch:2400 3/10...  Loss: 0.3655\n",
      "Epoch:2440 3/10...  Loss: 0.3736\n",
      "Epoch:2480 3/10...  Loss: 0.3897\n",
      "Epoch:2520 3/10...  Loss: 0.3790\n",
      "Epoch:2560 3/10...  Loss: 0.3983\n",
      "Epoch:2600 3/10...  Loss: 0.3565\n",
      "Epoch:2640 3/10...  Loss: 0.3723\n",
      "Epoch:2680 3/10...  Loss: 0.3469\n",
      "Epoch:2720 3/10...  Loss: 0.3436\n",
      "Epoch:2760 3/10...  Loss: 0.3368\n",
      "Epoch:2800 3/10...  Loss: 0.3621\n",
      "Epoch:2840 4/10...  Loss: 0.2110\n",
      "Epoch:2880 4/10...  Loss: 0.3460\n",
      "Epoch:2920 4/10...  Loss: 0.3654\n",
      "Epoch:2960 4/10...  Loss: 0.3457\n",
      "Epoch:3000 4/10...  Loss: 0.3663\n",
      "Epoch:3040 4/10...  Loss: 0.3585\n",
      "Epoch:3080 4/10...  Loss: 0.3344\n",
      "Epoch:3120 4/10...  Loss: 0.3299\n",
      "Epoch:3160 4/10...  Loss: 0.3521\n",
      "Epoch:3200 4/10...  Loss: 0.3510\n",
      "Epoch:3240 4/10...  Loss: 0.3463\n",
      "Epoch:3280 4/10...  Loss: 0.3507\n",
      "Epoch:3320 4/10...  Loss: 0.3222\n",
      "Epoch:3360 4/10...  Loss: 0.3829\n",
      "Epoch:3400 4/10...  Loss: 0.3688\n",
      "Epoch:3440 4/10...  Loss: 0.3390\n",
      "Epoch:3480 4/10...  Loss: 0.3277\n",
      "Epoch:3520 4/10...  Loss: 0.3639\n",
      "Epoch:3560 4/10...  Loss: 0.3552\n",
      "Epoch:3600 4/10...  Loss: 0.3275\n",
      "Epoch:3640 4/10...  Loss: 0.3301\n",
      "Epoch:3680 4/10...  Loss: 0.3546\n",
      "Epoch:3720 4/10...  Loss: 0.3222\n",
      "Epoch:3760 5/10...  Loss: 0.0696\n",
      "Epoch:3800 5/10...  Loss: 0.3325\n",
      "Epoch:3840 5/10...  Loss: 0.3240\n",
      "Epoch:3880 5/10...  Loss: 0.3371\n",
      "Epoch:3920 5/10...  Loss: 0.3175\n",
      "Epoch:3960 5/10...  Loss: 0.3363\n",
      "Epoch:4000 5/10...  Loss: 0.3212\n",
      "Epoch:4040 5/10...  Loss: 0.3345\n",
      "Epoch:4080 5/10...  Loss: 0.3240\n",
      "Epoch:4120 5/10...  Loss: 0.3256\n",
      "Epoch:4160 5/10...  Loss: 0.3455\n",
      "Epoch:4200 5/10...  Loss: 0.3121\n",
      "Epoch:4240 5/10...  Loss: 0.3324\n",
      "Epoch:4280 5/10...  Loss: 0.3333\n",
      "Epoch:4320 5/10...  Loss: 0.3167\n",
      "Epoch:4360 5/10...  Loss: 0.3429\n",
      "Epoch:4400 5/10...  Loss: 0.3000\n",
      "Epoch:4440 5/10...  Loss: 0.3385\n",
      "Epoch:4480 5/10...  Loss: 0.3317\n",
      "Epoch:4520 5/10...  Loss: 0.3252\n",
      "Epoch:4560 5/10...  Loss: 0.3232\n",
      "Epoch:4600 5/10...  Loss: 0.2936\n",
      "Epoch:4640 5/10...  Loss: 0.3358\n",
      "Epoch:4680 5/10...  Loss: 0.3323\n",
      "Epoch:4720 6/10...  Loss: 0.2108\n",
      "Epoch:4760 6/10...  Loss: 0.3220\n",
      "Epoch:4800 6/10...  Loss: 0.3042\n",
      "Epoch:4840 6/10...  Loss: 0.3252\n",
      "Epoch:4880 6/10...  Loss: 0.3231\n",
      "Epoch:4920 6/10...  Loss: 0.2950\n",
      "Epoch:4960 6/10...  Loss: 0.3023\n",
      "Epoch:5000 6/10...  Loss: 0.2807\n",
      "Epoch:5040 6/10...  Loss: 0.3192\n",
      "Epoch:5080 6/10...  Loss: 0.3223\n",
      "Epoch:5120 6/10...  Loss: 0.3446\n",
      "Epoch:5160 6/10...  Loss: 0.3061\n",
      "Epoch:5200 6/10...  Loss: 0.3141\n",
      "Epoch:5240 6/10...  Loss: 0.3500\n",
      "Epoch:5280 6/10...  Loss: 0.2965\n",
      "Epoch:5320 6/10...  Loss: 0.2954\n",
      "Epoch:5360 6/10...  Loss: 0.3043\n",
      "Epoch:5400 6/10...  Loss: 0.3166\n",
      "Epoch:5440 6/10...  Loss: 0.3240\n",
      "Epoch:5480 6/10...  Loss: 0.3156\n",
      "Epoch:5520 6/10...  Loss: 0.3178\n",
      "Epoch:5560 6/10...  Loss: 0.3209\n",
      "Epoch:5600 6/10...  Loss: 0.3014\n",
      "Epoch:5640 7/10...  Loss: 0.0861\n",
      "Epoch:5680 7/10...  Loss: 0.3045\n",
      "Epoch:5720 7/10...  Loss: 0.2803\n",
      "Epoch:5760 7/10...  Loss: 0.2774\n",
      "Epoch:5800 7/10...  Loss: 0.3100\n",
      "Epoch:5840 7/10...  Loss: 0.3307\n",
      "Epoch:5880 7/10...  Loss: 0.3232\n",
      "Epoch:5920 7/10...  Loss: 0.2985\n",
      "Epoch:5960 7/10...  Loss: 0.2906\n",
      "Epoch:6000 7/10...  Loss: 0.2870\n",
      "Epoch:6040 7/10...  Loss: 0.2637\n",
      "Epoch:6080 7/10...  Loss: 0.3009\n",
      "Epoch:6120 7/10...  Loss: 0.2931\n",
      "Epoch:6160 7/10...  Loss: 0.3201\n",
      "Epoch:6200 7/10...  Loss: 0.2932\n",
      "Epoch:6240 7/10...  Loss: 0.2643\n",
      "Epoch:6280 7/10...  Loss: 0.2892\n",
      "Epoch:6320 7/10...  Loss: 0.3002\n",
      "Epoch:6360 7/10...  Loss: 0.3071\n",
      "Epoch:6400 7/10...  Loss: 0.2799\n",
      "Epoch:6440 7/10...  Loss: 0.2788\n",
      "Epoch:6480 7/10...  Loss: 0.3329\n",
      "Epoch:6520 7/10...  Loss: 0.2789\n",
      "Epoch:6560 7/10...  Loss: 0.2784\n",
      "Epoch:6600 8/10...  Loss: 0.2513\n",
      "Epoch:6640 8/10...  Loss: 0.2964\n",
      "Epoch:6680 8/10...  Loss: 0.2674\n",
      "Epoch:6720 8/10...  Loss: 0.2719\n",
      "Epoch:6760 8/10...  Loss: 0.2729\n",
      "Epoch:6800 8/10...  Loss: 0.2778\n",
      "Epoch:6840 8/10...  Loss: 0.2827\n",
      "Epoch:6880 8/10...  Loss: 0.2730\n",
      "Epoch:6920 8/10...  Loss: 0.2822\n",
      "Epoch:6960 8/10...  Loss: 0.2718\n",
      "Epoch:7000 8/10...  Loss: 0.2695\n",
      "Epoch:7040 8/10...  Loss: 0.3088\n",
      "Epoch:7080 8/10...  Loss: 0.2836\n",
      "Epoch:7120 8/10...  Loss: 0.2832\n",
      "Epoch:7160 8/10...  Loss: 0.3108\n",
      "Epoch:7200 8/10...  Loss: 0.2704\n",
      "Epoch:7240 8/10...  Loss: 0.2692\n",
      "Epoch:7280 8/10...  Loss: 0.2808\n",
      "Epoch:7320 8/10...  Loss: 0.2952\n",
      "Epoch:7360 8/10...  Loss: 0.2988\n",
      "Epoch:7400 8/10...  Loss: 0.2838\n",
      "Epoch:7440 8/10...  Loss: 0.2841\n",
      "Epoch:7480 8/10...  Loss: 0.3071\n",
      "Epoch:7520 9/10...  Loss: 0.0939\n",
      "Epoch:7560 9/10...  Loss: 0.2936\n",
      "Epoch:7600 9/10...  Loss: 0.2579\n",
      "Epoch:7640 9/10...  Loss: 0.2733\n",
      "Epoch:7680 9/10...  Loss: 0.3031\n",
      "Epoch:7720 9/10...  Loss: 0.2834\n",
      "Epoch:7760 9/10...  Loss: 0.2972\n",
      "Epoch:7800 9/10...  Loss: 0.2575\n",
      "Epoch:7840 9/10...  Loss: 0.2611\n",
      "Epoch:7880 9/10...  Loss: 0.2682\n",
      "Epoch:7920 9/10...  Loss: 0.2895\n",
      "Epoch:7960 9/10...  Loss: 0.2673\n",
      "Epoch:8000 9/10...  Loss: 0.2754\n",
      "Epoch:8040 9/10...  Loss: 0.2618\n",
      "Epoch:8080 9/10...  Loss: 0.2839\n",
      "Epoch:8120 9/10...  Loss: 0.2408\n",
      "Epoch:8160 9/10...  Loss: 0.2446\n",
      "Epoch:8200 9/10...  Loss: 0.2996\n",
      "Epoch:8240 9/10...  Loss: 0.2841\n",
      "Epoch:8280 9/10...  Loss: 0.2843\n",
      "Epoch:8320 9/10...  Loss: 0.2894\n",
      "Epoch:8360 9/10...  Loss: 0.2833\n",
      "Epoch:8400 9/10...  Loss: 0.2584\n",
      "Epoch:8440 9/10...  Loss: 0.2706\n",
      "Epoch:8480 10/10...  Loss: 0.2723\n",
      "Epoch:8520 10/10...  Loss: 0.2621\n",
      "Epoch:8560 10/10...  Loss: 0.2647\n",
      "Epoch:8600 10/10...  Loss: 0.2519\n",
      "Epoch:8640 10/10...  Loss: 0.2586\n",
      "Epoch:8680 10/10...  Loss: 0.2731\n",
      "Epoch:8720 10/10...  Loss: 0.2615\n",
      "Epoch:8760 10/10...  Loss: 0.2725\n",
      "Epoch:8800 10/10...  Loss: 0.2492\n",
      "Epoch:8840 10/10...  Loss: 0.2594\n",
      "Epoch:8880 10/10...  Loss: 0.2741\n",
      "Epoch:8920 10/10...  Loss: 0.2681\n",
      "Epoch:8960 10/10...  Loss: 0.2798\n",
      "Epoch:9000 10/10...  Loss: 0.2486\n",
      "Epoch:9040 10/10...  Loss: 0.2619\n",
      "Epoch:9080 10/10...  Loss: 0.2682\n",
      "Epoch:9120 10/10...  Loss: 0.2493\n",
      "Epoch:9160 10/10...  Loss: 0.2605\n",
      "Epoch:9200 10/10...  Loss: 0.2903\n",
      "Epoch:9240 10/10...  Loss: 0.2752\n",
      "Epoch:9280 10/10...  Loss: 0.2510\n",
      "Epoch:9320 10/10...  Loss: 0.2726\n",
      "Epoch:9360 10/10...  Loss: 0.2950\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the network here\n",
    "\n",
    "epochs = 10\n",
    "print_every = 40\n",
    "steps = 0\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in iter(trainloader):   #MNIST data is 60K test and 10K test. 64 (batch)*938 step~60K, since it shuffle should not be covering everythong probably\n",
    "        steps += 1\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()  #loss is scalar tensor, to get it summ with running loss need to get loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch:{} {}/{}... \".format(steps,e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 204,
       "width": 423
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test out your network!\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# TODO: Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "ps = F.softmax(logits, dim=1)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your network is trained, you'll want to save it to disk so you can load it later instead of training it again. Obviously, it's impractical to train a network every time you need one. In practice, you'll train it once, save the model, then reload it for further training or making predictions. In the next part, I'll show you how to save and load trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 train images: 89 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "#ps = F.softmax(logits, dim=1)\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        img, label_ = data\n",
    "\n",
    "        img = img.resize_(64, 784)   #64 image at a time,.\n",
    "\n",
    "        outputs = model.forward(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        #predicted = F.softmax(outputs, dim=1)\n",
    "\n",
    "        #print('label',label_)\n",
    "        #print(outputs)\n",
    "        #print('predicted',predicted)\n",
    "        #print(labels.size(0))\n",
    "       \n",
    "        if (total<=50000):    #have to put this since last iterations there are prediction but not labels\n",
    "            total += label_.size(0)   #add total=64+64+..\n",
    "            #print(label_.size())\n",
    "            #print(predicted.size())\n",
    "\n",
    "            correct += (predicted == label_).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 train images: %d %%' % (\n",
    "    100 * correct / total))     #loss below 0.4 by increasing epoch from 3 to 10, adding two more layer hidden unit increase from 81 to 86%\n",
    "                                # adding momentum 0.9 siginificantly improve convergence rate increase accuracy from 86% to 89% after 2-3 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 train images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "#ps = F.softmax(logits, dim=1)\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        img, label_ = data\n",
    "\n",
    "        img = img.resize_(64, 784)   #64 image at a time,.\n",
    "\n",
    "        outputs = model.forward(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        #predicted = F.softmax(outputs, dim=1)\n",
    "\n",
    "        #print('label',label_)\n",
    "        #print(outputs)\n",
    "        #print('predicted',predicted)\n",
    "        #print(labels.size(0))\n",
    "       \n",
    "        if (total<=9000):    #have to put this since last iterations there are prediction but not labels\n",
    "            total += label_.size(0)   #add total=64+64+..\n",
    "            #print(label_.size())\n",
    "            #print(predicted.size())\n",
    "\n",
    "            correct += (predicted == label_).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing the optimizer to ADA#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                 weight_decay=0, amsgrad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:40 1/10...  Loss: 0.3388\n",
      "Epoch:80 1/10...  Loss: 0.2869\n",
      "Epoch:120 1/10...  Loss: 0.2714\n",
      "Epoch:160 1/10...  Loss: 0.2855\n",
      "Epoch:200 1/10...  Loss: 0.2815\n",
      "Epoch:240 1/10...  Loss: 0.2695\n",
      "Epoch:280 1/10...  Loss: 0.2780\n",
      "Epoch:320 1/10...  Loss: 0.3057\n",
      "Epoch:360 1/10...  Loss: 0.3179\n",
      "Epoch:400 1/10...  Loss: 0.2952\n",
      "Epoch:440 1/10...  Loss: 0.3076\n",
      "Epoch:480 1/10...  Loss: 0.3064\n",
      "Epoch:520 1/10...  Loss: 0.3041\n",
      "Epoch:560 1/10...  Loss: 0.3234\n",
      "Epoch:600 1/10...  Loss: 0.3050\n",
      "Epoch:640 1/10...  Loss: 0.2679\n",
      "Epoch:680 1/10...  Loss: 0.2947\n",
      "Epoch:720 1/10...  Loss: 0.2936\n",
      "Epoch:760 1/10...  Loss: 0.2742\n",
      "Epoch:800 1/10...  Loss: 0.2864\n",
      "Epoch:840 1/10...  Loss: 0.3070\n",
      "Epoch:880 1/10...  Loss: 0.2811\n",
      "Epoch:920 1/10...  Loss: 0.2779\n",
      "Epoch:960 2/10...  Loss: 0.1497\n",
      "Epoch:1000 2/10...  Loss: 0.2755\n",
      "Epoch:1040 2/10...  Loss: 0.2883\n",
      "Epoch:1080 2/10...  Loss: 0.2932\n",
      "Epoch:1120 2/10...  Loss: 0.2727\n",
      "Epoch:1160 2/10...  Loss: 0.2860\n",
      "Epoch:1200 2/10...  Loss: 0.2689\n",
      "Epoch:1240 2/10...  Loss: 0.2959\n",
      "Epoch:1280 2/10...  Loss: 0.2681\n",
      "Epoch:1320 2/10...  Loss: 0.2886\n",
      "Epoch:1360 2/10...  Loss: 0.2786\n",
      "Epoch:1400 2/10...  Loss: 0.2944\n",
      "Epoch:1440 2/10...  Loss: 0.2761\n",
      "Epoch:1480 2/10...  Loss: 0.2977\n",
      "Epoch:1520 2/10...  Loss: 0.2761\n",
      "Epoch:1560 2/10...  Loss: 0.2697\n",
      "Epoch:1600 2/10...  Loss: 0.2716\n",
      "Epoch:1640 2/10...  Loss: 0.2750\n",
      "Epoch:1680 2/10...  Loss: 0.2929\n",
      "Epoch:1720 2/10...  Loss: 0.2963\n",
      "Epoch:1760 2/10...  Loss: 0.2662\n",
      "Epoch:1800 2/10...  Loss: 0.2842\n",
      "Epoch:1840 2/10...  Loss: 0.2809\n",
      "Epoch:1880 3/10...  Loss: 0.0351\n",
      "Epoch:1920 3/10...  Loss: 0.2566\n",
      "Epoch:1960 3/10...  Loss: 0.2595\n",
      "Epoch:2000 3/10...  Loss: 0.2779\n",
      "Epoch:2040 3/10...  Loss: 0.2586\n",
      "Epoch:2080 3/10...  Loss: 0.2572\n",
      "Epoch:2120 3/10...  Loss: 0.2553\n",
      "Epoch:2160 3/10...  Loss: 0.2721\n",
      "Epoch:2200 3/10...  Loss: 0.2597\n",
      "Epoch:2240 3/10...  Loss: 0.2604\n",
      "Epoch:2280 3/10...  Loss: 0.2717\n",
      "Epoch:2320 3/10...  Loss: 0.2702\n",
      "Epoch:2360 3/10...  Loss: 0.2731\n",
      "Epoch:2400 3/10...  Loss: 0.2773\n",
      "Epoch:2440 3/10...  Loss: 0.2922\n",
      "Epoch:2480 3/10...  Loss: 0.2532\n",
      "Epoch:2520 3/10...  Loss: 0.2643\n",
      "Epoch:2560 3/10...  Loss: 0.2679\n",
      "Epoch:2600 3/10...  Loss: 0.2850\n",
      "Epoch:2640 3/10...  Loss: 0.2680\n",
      "Epoch:2680 3/10...  Loss: 0.2841\n",
      "Epoch:2720 3/10...  Loss: 0.2517\n",
      "Epoch:2760 3/10...  Loss: 0.2666\n",
      "Epoch:2800 3/10...  Loss: 0.2855\n",
      "Epoch:2840 4/10...  Loss: 0.1673\n",
      "Epoch:2880 4/10...  Loss: 0.2499\n",
      "Epoch:2920 4/10...  Loss: 0.2461\n",
      "Epoch:2960 4/10...  Loss: 0.2574\n",
      "Epoch:3000 4/10...  Loss: 0.2557\n",
      "Epoch:3040 4/10...  Loss: 0.2503\n",
      "Epoch:3080 4/10...  Loss: 0.2378\n",
      "Epoch:3120 4/10...  Loss: 0.2687\n",
      "Epoch:3160 4/10...  Loss: 0.2547\n",
      "Epoch:3200 4/10...  Loss: 0.2514\n",
      "Epoch:3240 4/10...  Loss: 0.2869\n",
      "Epoch:3280 4/10...  Loss: 0.2424\n",
      "Epoch:3320 4/10...  Loss: 0.2901\n",
      "Epoch:3360 4/10...  Loss: 0.2623\n",
      "Epoch:3400 4/10...  Loss: 0.2531\n",
      "Epoch:3440 4/10...  Loss: 0.2437\n",
      "Epoch:3480 4/10...  Loss: 0.2780\n",
      "Epoch:3520 4/10...  Loss: 0.2354\n",
      "Epoch:3560 4/10...  Loss: 0.2945\n",
      "Epoch:3600 4/10...  Loss: 0.2675\n",
      "Epoch:3640 4/10...  Loss: 0.2726\n",
      "Epoch:3680 4/10...  Loss: 0.2473\n",
      "Epoch:3720 4/10...  Loss: 0.2588\n",
      "Epoch:3760 5/10...  Loss: 0.0429\n",
      "Epoch:3800 5/10...  Loss: 0.2427\n",
      "Epoch:3840 5/10...  Loss: 0.2425\n",
      "Epoch:3880 5/10...  Loss: 0.2215\n",
      "Epoch:3920 5/10...  Loss: 0.2402\n",
      "Epoch:3960 5/10...  Loss: 0.2446\n",
      "Epoch:4000 5/10...  Loss: 0.2355\n",
      "Epoch:4040 5/10...  Loss: 0.2706\n",
      "Epoch:4080 5/10...  Loss: 0.2287\n",
      "Epoch:4120 5/10...  Loss: 0.2745\n",
      "Epoch:4160 5/10...  Loss: 0.2730\n",
      "Epoch:4200 5/10...  Loss: 0.2343\n",
      "Epoch:4240 5/10...  Loss: 0.2384\n",
      "Epoch:4280 5/10...  Loss: 0.2426\n",
      "Epoch:4320 5/10...  Loss: 0.2666\n",
      "Epoch:4360 5/10...  Loss: 0.2848\n",
      "Epoch:4400 5/10...  Loss: 0.2810\n",
      "Epoch:4440 5/10...  Loss: 0.2532\n",
      "Epoch:4480 5/10...  Loss: 0.2912\n",
      "Epoch:4520 5/10...  Loss: 0.2613\n",
      "Epoch:4560 5/10...  Loss: 0.2447\n",
      "Epoch:4600 5/10...  Loss: 0.2354\n",
      "Epoch:4640 5/10...  Loss: 0.2539\n",
      "Epoch:4680 5/10...  Loss: 0.2434\n",
      "Epoch:4720 6/10...  Loss: 0.1817\n",
      "Epoch:4760 6/10...  Loss: 0.2569\n",
      "Epoch:4800 6/10...  Loss: 0.2355\n",
      "Epoch:4840 6/10...  Loss: 0.2186\n",
      "Epoch:4880 6/10...  Loss: 0.2255\n",
      "Epoch:4920 6/10...  Loss: 0.2302\n",
      "Epoch:4960 6/10...  Loss: 0.2694\n",
      "Epoch:5000 6/10...  Loss: 0.2550\n",
      "Epoch:5040 6/10...  Loss: 0.2300\n",
      "Epoch:5080 6/10...  Loss: 0.2429\n",
      "Epoch:5120 6/10...  Loss: 0.2548\n",
      "Epoch:5160 6/10...  Loss: 0.2655\n",
      "Epoch:5200 6/10...  Loss: 0.2395\n",
      "Epoch:5240 6/10...  Loss: 0.2264\n",
      "Epoch:5280 6/10...  Loss: 0.2369\n",
      "Epoch:5320 6/10...  Loss: 0.2424\n",
      "Epoch:5360 6/10...  Loss: 0.2593\n",
      "Epoch:5400 6/10...  Loss: 0.2516\n",
      "Epoch:5440 6/10...  Loss: 0.2344\n",
      "Epoch:5480 6/10...  Loss: 0.2157\n",
      "Epoch:5520 6/10...  Loss: 0.2423\n",
      "Epoch:5560 6/10...  Loss: 0.2504\n",
      "Epoch:5600 6/10...  Loss: 0.2657\n",
      "Epoch:5640 7/10...  Loss: 0.0641\n",
      "Epoch:5680 7/10...  Loss: 0.2310\n",
      "Epoch:5720 7/10...  Loss: 0.2232\n",
      "Epoch:5760 7/10...  Loss: 0.2171\n",
      "Epoch:5800 7/10...  Loss: 0.2409\n",
      "Epoch:5840 7/10...  Loss: 0.2252\n",
      "Epoch:5880 7/10...  Loss: 0.2399\n",
      "Epoch:5920 7/10...  Loss: 0.2394\n",
      "Epoch:5960 7/10...  Loss: 0.2281\n",
      "Epoch:6000 7/10...  Loss: 0.2157\n",
      "Epoch:6040 7/10...  Loss: 0.2284\n",
      "Epoch:6080 7/10...  Loss: 0.2108\n",
      "Epoch:6120 7/10...  Loss: 0.2736\n",
      "Epoch:6160 7/10...  Loss: 0.2261\n",
      "Epoch:6200 7/10...  Loss: 0.2450\n",
      "Epoch:6240 7/10...  Loss: 0.2379\n",
      "Epoch:6280 7/10...  Loss: 0.2235\n",
      "Epoch:6320 7/10...  Loss: 0.2378\n",
      "Epoch:6360 7/10...  Loss: 0.2267\n",
      "Epoch:6400 7/10...  Loss: 0.2439\n",
      "Epoch:6440 7/10...  Loss: 0.2365\n",
      "Epoch:6480 7/10...  Loss: 0.2358\n",
      "Epoch:6520 7/10...  Loss: 0.2520\n",
      "Epoch:6560 7/10...  Loss: 0.2663\n",
      "Epoch:6600 8/10...  Loss: 0.1797\n",
      "Epoch:6640 8/10...  Loss: 0.2290\n",
      "Epoch:6680 8/10...  Loss: 0.2236\n",
      "Epoch:6720 8/10...  Loss: 0.2084\n",
      "Epoch:6760 8/10...  Loss: 0.2449\n",
      "Epoch:6800 8/10...  Loss: 0.2198\n",
      "Epoch:6840 8/10...  Loss: 0.2055\n",
      "Epoch:6880 8/10...  Loss: 0.2553\n",
      "Epoch:6920 8/10...  Loss: 0.2364\n",
      "Epoch:6960 8/10...  Loss: 0.2320\n",
      "Epoch:7000 8/10...  Loss: 0.2221\n",
      "Epoch:7040 8/10...  Loss: 0.2068\n",
      "Epoch:7080 8/10...  Loss: 0.2244\n",
      "Epoch:7120 8/10...  Loss: 0.2456\n",
      "Epoch:7160 8/10...  Loss: 0.2434\n",
      "Epoch:7200 8/10...  Loss: 0.2404\n",
      "Epoch:7240 8/10...  Loss: 0.2257\n",
      "Epoch:7280 8/10...  Loss: 0.2363\n",
      "Epoch:7320 8/10...  Loss: 0.2077\n",
      "Epoch:7360 8/10...  Loss: 0.2252\n",
      "Epoch:7400 8/10...  Loss: 0.2525\n",
      "Epoch:7440 8/10...  Loss: 0.2277\n",
      "Epoch:7480 8/10...  Loss: 0.2580\n",
      "Epoch:7520 9/10...  Loss: 0.0776\n",
      "Epoch:7560 9/10...  Loss: 0.2123\n",
      "Epoch:7600 9/10...  Loss: 0.2243\n",
      "Epoch:7640 9/10...  Loss: 0.2186\n",
      "Epoch:7680 9/10...  Loss: 0.2246\n",
      "Epoch:7720 9/10...  Loss: 0.2232\n",
      "Epoch:7760 9/10...  Loss: 0.1953\n",
      "Epoch:7800 9/10...  Loss: 0.2418\n",
      "Epoch:7840 9/10...  Loss: 0.2040\n",
      "Epoch:7880 9/10...  Loss: 0.2461\n",
      "Epoch:7920 9/10...  Loss: 0.2391\n",
      "Epoch:7960 9/10...  Loss: 0.2165\n",
      "Epoch:8000 9/10...  Loss: 0.2018\n",
      "Epoch:8040 9/10...  Loss: 0.2196\n",
      "Epoch:8080 9/10...  Loss: 0.2153\n",
      "Epoch:8120 9/10...  Loss: 0.2123\n",
      "Epoch:8160 9/10...  Loss: 0.2188\n",
      "Epoch:8200 9/10...  Loss: 0.2316\n",
      "Epoch:8240 9/10...  Loss: 0.2024\n",
      "Epoch:8280 9/10...  Loss: 0.2149\n",
      "Epoch:8320 9/10...  Loss: 0.2191\n",
      "Epoch:8360 9/10...  Loss: 0.2312\n",
      "Epoch:8400 9/10...  Loss: 0.2234\n",
      "Epoch:8440 9/10...  Loss: 0.2306\n",
      "Epoch:8480 10/10...  Loss: 0.1794\n",
      "Epoch:8520 10/10...  Loss: 0.2090\n",
      "Epoch:8560 10/10...  Loss: 0.2217\n",
      "Epoch:8600 10/10...  Loss: 0.2135\n",
      "Epoch:8640 10/10...  Loss: 0.2032\n",
      "Epoch:8680 10/10...  Loss: 0.1810\n",
      "Epoch:8720 10/10...  Loss: 0.2244\n",
      "Epoch:8760 10/10...  Loss: 0.2110\n",
      "Epoch:8800 10/10...  Loss: 0.2604\n",
      "Epoch:8840 10/10...  Loss: 0.2141\n",
      "Epoch:8880 10/10...  Loss: 0.2225\n",
      "Epoch:8920 10/10...  Loss: 0.2093\n",
      "Epoch:8960 10/10...  Loss: 0.2301\n",
      "Epoch:9000 10/10...  Loss: 0.2111\n",
      "Epoch:9040 10/10...  Loss: 0.2291\n",
      "Epoch:9080 10/10...  Loss: 0.2251\n",
      "Epoch:9120 10/10...  Loss: 0.2234\n",
      "Epoch:9160 10/10...  Loss: 0.2088\n",
      "Epoch:9200 10/10...  Loss: 0.2095\n",
      "Epoch:9240 10/10...  Loss: 0.2010\n",
      "Epoch:9280 10/10...  Loss: 0.2023\n",
      "Epoch:9320 10/10...  Loss: 0.2098\n",
      "Epoch:9360 10/10...  Loss: 0.2306\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Train the network here\n",
    "\n",
    "epochs = 10\n",
    "print_every = 40\n",
    "steps = 0\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in iter(trainloader):   #MNIST data is 60K test and 10K test. 64 (batch)*938 step~60K, since it shuffle should not be covering everythong probably\n",
    "        steps += 1\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        running_loss += loss.item()  #loss is scalar tensor, to get it summ with running loss need to get loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch:{} {}/{}... \".format(steps,e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 train images: 92 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "#ps = F.softmax(logits, dim=1)\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        img, label_ = data\n",
    "\n",
    "        img = img.resize_(64, 784)   #64 image at a time,.\n",
    "\n",
    "        outputs = model.forward(img)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        #predicted = F.softmax(outputs, dim=1)\n",
    "\n",
    "        #print('label',label_)\n",
    "        #print(outputs)\n",
    "        #print('predicted',predicted)\n",
    "        #print(labels.size(0))\n",
    "       \n",
    "        if (total<=50000):    #have to put this since last iterations there are prediction but not labels\n",
    "            total += label_.size(0)   #add total=64+64+..\n",
    "            #print(label_.size())\n",
    "            #print(predicted.size())\n",
    "\n",
    "            correct += (predicted == label_).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 train images: %d %%' % (\n",
    "    100 * correct / total))     #loss below 0.4 by increasing epoch from 3 to 10, adding two more layer hidden unit increase from 81 to 86%\n",
    "#switching to ADAM increased from SGD 89% to 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
