{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing IMDB Data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(113)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data\n",
    "This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at. We've set it at 1000, but feel free to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (it's preloaded in Keras)\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1500,seed=113)\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
    "#                                                       num_words=1050,\n",
    "#                                                       skip_top=30,\n",
    "#                                                       maxlen=None,\n",
    "#                                                       seed=113,\n",
    "#                                                       start_char=1,\n",
    "#                                                       oov_char=30,\n",
    "#                                                       index_from=3)\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
    "#                                                       num_words=None,\n",
    "#                                                       skip_top=0,\n",
    "#                                                       maxlen=None,\n",
    "#                                                       seed=113,\n",
    "#                                                       start_char=1,\n",
    "#                                                       oov_char=2,\n",
    "#                                                       index_from=3)    \n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examining the data\n",
    "Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n",
    "\n",
    "The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 1385, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# import keras\n",
    "# NUM_WORDS=1000 # only use top 1000 words\n",
    "# INDEX_FROM=3   # word index offset\n",
    "\n",
    "# train,test = keras.datasets.imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
    "# train_x,train_y = train\n",
    "# test_x,test_y = test\n",
    "\n",
    "# word_to_id = keras.datasets.imdb.get_word_index()\n",
    "# word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "# word_to_id[\"<PAD>\"] = 0\n",
    "# word_to_id[\"<START>\"] = 1\n",
    "# word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "# id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "# print(' '.join(id_to_word[id] for id in train_x[0] ))\n",
    "# The punctuation is missing, but that's all:\n",
    "\n",
    "# \"<START> this film was just brilliant casting <UNK> <UNK> story\n",
    "#  direction <UNK> really <UNK> the part they played and you could just\n",
    "#  imagine being there robert <UNK> is an amazing actor ...\"\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the as you with out themselves powerful and loves their becomes and had and of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every and visual movie except her was several of enough more with is now and film as you of and and unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of and and with heart had and they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over and for anyone of and br and to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an and she he should is thought and but of script you not while history he heart to real at and but when from one bit then have two of script their with her nobody most that with wasn't to with and acting watch an for with and film want an\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_FROM=0\n",
    "word_to_idn = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "#word_to_idn[\"<PAD>\"] = 0\n",
    "#word_to_idn[\"<START>\"] = 1\n",
    "#word_to_idn[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_wordn = {value:key for key,value in word_to_idn.items()}\n",
    "print(' '.join(id_to_wordn[id] for id in x_train[0] ))\n",
    "y_train[0]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'the'), (2, 'and'), (3, 'a'), (4, 'of'), (5, 'to'), (6, 'is'), (7, 'br'), (8, 'in'), (9, 'it'), (10, 'i'), (11, 'this'), (12, 'that'), (13, 'was'), (14, 'as'), (15, 'for'), (16, 'with'), (17, 'movie'), (18, 'but'), (19, 'film'), (20, 'on'), (21, 'not'), (22, 'you'), (23, 'are'), (24, 'his'), (25, 'have'), (26, 'he'), (27, 'be'), (28, 'one'), (29, 'all'), (30, 'at')]\n",
      "\n",
      "[(1001, 'inside'), (1002, 'outside'), (1003, 'nudity'), (1004, 'reasons'), (1005, 'ideas'), (1006, 'twist'), (1007, 'western'), (1008, 'front'), (1009, 'missing'), (1010, 'boys'), (1011, 'match'), (1012, 'deserves'), (1013, 'jane'), (1014, 'expecting'), (1015, 'fairly'), (1016, 'villain'), (1017, 'talented'), (1018, 'married'), (1019, 'ben'), (1020, 'success'), (1021, 'william'), (1022, 'unlike'), (1023, 'rich'), (1024, 'attempts'), (1025, 'spoilers'), (1026, 'list'), (1027, 'manages'), (1028, 'social'), (1029, 'odd'), (1030, 'recently')]\n",
      "\n",
      "[(88555, 'expeditious'), (88556, \"'half\"), (88557, 'lederer'), (88558, \"bearings'\"), (88559, 'wight'), (88560, 'contradictors'), (88561, 'amitabhs'), (88562, \"olan's\"), (88563, 'fountainhead'), (88564, 'reble'), (88565, 'percival'), (88566, 'lubricated'), (88567, 'heralding'), (88568, \"baywatch'\"), (88569, 'odilon'), (88570, \"'solve'\"), (88571, \"guard's\"), (88572, \"nemesis'\"), (88573, 'airsoft'), (88574, 'urrrghhh'), (88575, 'ev'), (88576, 'chicatillo'), (88577, 'transacting'), (88578, 'sics'), (88579, 'wheelers'), (88580, \"pipe's\"), (88581, 'copywrite'), (88582, 'artbox'), (88583, \"voorhees'\")]\n"
     ]
    }
   ],
   "source": [
    "#word_to_id.items()\n",
    "items = sorted(((v, k) for k, v in word_to_id.items()), reverse=False)\n",
    "print(items[0:30])\n",
    "print('')\n",
    "print(items[1000:1030])\n",
    "print('')\n",
    "print(items[-30:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-hot encoding the output\n",
    "Here, we'll turn the input vectors into (0,1)-vectors. For example, if the pre-processed vector contains the number 14, then in the processed vector, the 14th entry will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 1385, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output into vector mode, each of length 1000\n",
    "print(x_train[0])\n",
    "tokenizer = Tokenizer(num_words=1500)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll also one-hot encode the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the  model architecture\n",
    "Build a model here using sequential. Feel free to experiment with different layers and sizes! Also, experiment adding dropout to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               192128    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 200,514\n",
      "Trainable params: 200,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build the model architecture\n",
    "model=Sequential()\n",
    "\n",
    "\n",
    "# Add required layers\n",
    "\n",
    "model.add(Dense(128, activation='relu', input_shape=(1500,)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# TODO: Compile the model using a loss function and an optimizer.\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the model\n",
    "Run the model here. Experiment with different batch_size, and number of epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcf2643978>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
    "model.fit(x_train, y_train, epochs=250, batch_size=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating the model\n",
    "This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.85464\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 128)               192128    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 202,530\n",
      "Trainable params: 202,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy:  0.85456\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build the model architecture\n",
    "model2=Sequential()\n",
    "\n",
    "\n",
    "# Add required layers\n",
    "\n",
    "model2.add(Dense(128, activation='relu', input_shape=(1500,)))\n",
    "model2.add(Dropout(.2))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(.2))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dropout(.1))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# TODO: Compile the model using a loss function and an optimizer.\n",
    "\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "\n",
    "# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
    "model2.fit(x_train, y_train, epochs=300, batch_size=1000, verbose=0)\n",
    "\n",
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
